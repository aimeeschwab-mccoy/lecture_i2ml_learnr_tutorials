## Bagging and Random Forests


### Study Goals

*Theoretical (T)*

- Learn why and how bagging works
-
- Get to know the differences between bagging and random forests
-

*Practical (P)*

- Know how to train a random forest model using `mlr`



### Preparation

1.  *(T)* Watch the following videos (sorry, rather low volume...):
    <center>
    ![](https://youtu.be/e4twP-lMPVI){width="75%"}
    </center>
    <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/slides-pdf/slides-intro-performance.pdf" target="_blank">Slideset Random Forest 1</a>
    <center>
    ![](https://youtu.be/YPkNPGrdGoY){width="75%"}
    </center>
    <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/slides-pdf/slides-measures.pdf" target="_blank">Slideset Random Forest 2</a>

### Exercises

#### *(T)* Quiz

```{r random forest-quiz1, echo=FALSE}
question("Which statements are true?",
  answer("Bagging works best for unstable learners.", correct = TRUE),
  answer("For stable estimation methods, bagging mostly degrades performance."),
  answer("Random forests is a kind of bagging model for trees.", correct = TRUE),
  answer("The OOB error is similar to cross-validation estimation. It can also be used for a quicker model selection.", correct = TRUE),
  answer("In random forests for regression, a good rule of thumb is to use mtry$=\\sqrt(p)$", correct = TRUE),
  answer("Often works well enough.", correct = TRUE),
  answer("It can work also on high-dimensional data.", correct = TRUE),
  answer("Proximities are used in replacing missing data, but not locating outliers."),
  answer("For each variable, the improvement is accumulated over all trees for the importance measure.", correct = TRUE),
  answer("The random forest is a bad out of the box model and requires tuning of hyperparameters."),
  answer("The random forest is often used as base-line model due to its good out of the box performance.", correct = TRUE)
)
```


#### *(P)* Create the `mlr` learner

Create a random forest task with the `spirals` data using the `randomForest` function from package `randomForest`:

```{r randomForest-definition, exercise=TRUE, exercise.lines=5, exercise.checker=createChecker("spirals_task")}
set.seed(1337)
spirals = mlbench.spirals(500, sd = 0.1)
spirals = as.data.frame(spirals)
spirals_task =
```

```{r randomForest-definition-hint-1, eval=FALSE}
# Use the 'makeClassifTask' function of mlr
makeClassifTask(...)
```


```{r randomForest-definition-check}
set.seed(1337)
spirals = mlbench.spirals(500, sd = 0.1)
spirals = as.data.frame(spirals)
spirals_task = makeClassifTask(data = spirals, target = "classes")
```


#### *(P)* Train the `mlr` learner

Now train the learner on the spirals_task:
```{r randomForest-definition1, exercise=TRUE, exercise.lines=5, exercise.checker=createChecker("rf_learner")}
rf_learner =
```

```{r randomForest-definition1-hint-1, eval=FALSE}
# Use the 'makeLearner' function of mlr
makeLearner(...)
```

```{r randomForest-definition1-check}
rf_learner = makeLearner("classif.randomForest")
```


#### *(P)* Visualize decision boundaries

Again, define the `rf_learner` and visualize the prediction of the learner with `plotLearnerPrediction`. Rerun the code for different `ntrees`. What can you observe by varying the hyperparameter?

```{r, include=FALSE}
set.seed(1337)
spirals = mlbench.spirals(500, sd = 0.1)
spirals = as.data.frame(spirals)
spirals_task = makeClassifTask(data = spirals, target = "classes")
rf_learner = makeLearner("classif.randomForest")
```

```{r randomForest-definition-visualization, exercise=TRUE}
ntrees = c(1, 10, 20, 100, 1000)

for (nt in ntrees) {
  print(plotLearnerPrediction(learner = , task = , ntree = nt))
  pause()
}
```






