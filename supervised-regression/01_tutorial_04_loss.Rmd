## Loss Functions

### Study Goals

*Theoretical (T)*

- Learn what a model uses to evaluate how good it performs on the data
- Learn how the choice of loss function affects properties of the learner

### Preparation

1. *(T)* Watch the following video  (sorry, rather low volume...):
    <center>
    ![](https://youtu.be/PIj0HR4lUOg){width="75%"}
    </center>
    <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/slides-pdf/slides-loss.pdf" target="_blank">Slideset</a>

### Exercises

#### *(T)* Quiz

```{r loss-quiz, echo=FALSE}
question("Which statements are true?",
  answer("Any model can use any arbitrary loss function."),
  answer("The empirical risk $\\mathcal{R}_\\text{emp}(f)$ is defined by the loss
         function.",
         correct = TRUE),
  answer("The loss function defines the evaluation part of a learner (inducer).",
         correct = TRUE),
  answer("Loss functions are always symmetric around zero."),
  answer("Loss functions are always positive.",
         correct = TRUE),
  answer("Loss functions are always smaller than 1."),
  answer("$L(y, f(x))$ quantifies how accurately a model predicts the target
         variable on the training data set."),
  answer("$\\mathcal{R}_\\text{emp}(f)$ tells us exactly how accurately a model
         will predict new observations."),
  answer("Empirical risk minimization is a very general mathematical framework
         that turns 'finding a good model' into a mathematically tractable
         optimization problem.",
         correct = TRUE),
  answer("Since empirical risk minimization is a completely abstract and very
         general mathematical procedure, the choice of loss function should not
         depend on background knowledge about the data set at hand or what the
         model is going to be used for."),
  answer("If two models achieve the same empirical risk, they yield identical
         predictions."),
  answer("The absolute loss function is more sensitive to outliers than
         the quadratic loss function."),
  answer("How difficult the optimization of a learner is depends strongly on the
         properties of its loss function.",
         correct = TRUE)
)
```
