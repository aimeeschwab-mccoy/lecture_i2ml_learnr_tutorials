## More Methods

### Study Goals

*Theoretical (T)*

- Become familiar with LDA, QDA, k-NN and the Naive Bayes classifier


*Practical (P)*

- Get to know how to fit classifiers in `mlr`

### Preparation

1.  Watch the following video  (sorry, rather low volume...):
    <center>
    ![Discriminant analysis](){width="75%"}
    ![Naive bayes](){width="75%"}
    ![k-NN](){width="75%"}
    </center>

### Exercises

#### *(T)* Quiz

```{r classif-approaches-quiz, echo=FALSE}
question("Which statements are true?",
    answer("In LDA, each class density is modeled as a multivariate Gaussian with unequal covariance."),
    answer("LDA is a linear classifier", correct = TRUE),
    answer("LDA follows a generative approach", correct = TRUE),
    answer("In QDA, each class density is modeled as a multivariate Gaussian with equal covariance"),
    answer("QDA follows a generative approach", correct = TRUE),
    answer("QDA requires estimation of more parameters than LDA", correct = TRUE),
    answer("Naive Bayes assumes that the features are independent within each outcome class y.", correct = TRUE),
    answer("Naive Bayes follows a generative approach", correct = TRUE),
    answer("k-NN can be used in regression and classification", correct = TRUE),
    answer("k-NN is a probabilistic classifier", correct = TRUE)
)
```

#### *(P)* Qualitative comparison of LDA, QDA, and naive Bayes

In this demo we want to compare LDA, QDA, and naive Bayes by looking at the decision boundaries (hint: with `listLearners(properties = "multiclass")` you get a list with all available learners suited for multiclass classification). Use `plotLearnerPrediction()` to visualize the decision boundaries for the features `Sepal.Length` and `Sepal.Width`. You can use the build in iris task `iris.task` of `mlr`. Store the plot for each model and plot them underneath each other with `grid.arrange()` from the `gridExtra` package:


```{r generative-approaches, exercise=TRUE, exercise.lines=8, fig.height=8}
set.seed(123)
gg1 = plotLearnerPrediction(..., task = iris.task, features = ...)
gg2 = plotLearnerPrediction(..., task = iris.task, features = ...)
gg3 = plotLearnerPrediction(..., task = iris.task, features = ...)

gridExtra::grid.arrange(gg1, gg2, gg3, ncol = 1)
```

```{r generative-approaches-hint-1}
# The mlr learner are:
"classif.lda"
"classif.qda"
"classif.naiveBayes"
# You can directly use the string instead of a learner.
```

```{r generative-approaches-hint-2}
# You can specify the used features in 'plotLearnerPrediction()' by setting the features argument:
plotLearnerPrediction("classif.lda", task = iris.task, features = c("Sepal.Length", "Sepal.Width"))
```


```{r generative-approaches-solution}
gg1 = plotLearnerPrediction("classif.lda", task = iris.task, features = c("Sepal.Length", "Sepal.Width"))
gg2 = plotLearnerPrediction("classif.qda", task = iris.task, features = c("Sepal.Length", "Sepal.Width"))
gg3 = plotLearnerPrediction("classif.naiveBayes", task = iris.task, features = c("Sepal.Length", "Sepal.Width"))

gridExtra::grid.arrange(gg1, gg2, gg3, ncol = 1)
```

```{r lda-qda-naiveBayes-quiz, echo=FALSE}
question("What can you observe?",
  answer("The decision boundaries of all classifiers looks equal."),
  answer("The naive Bayes classifier has linear decision boundaries due to the simple construction."),
  answer("LDA is the only classifier with linear decision boundaries.", correct = TRUE),
  answer("QDA has non-linear decision boundaries due to the different covariances in each class.", correct = TRUE)
)
```
